---
phase: 04-test-coverage
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - main_test.go
  - testdata/valid_config.yaml
  - testdata/invalid_config.yaml
autonomous: true

must_haves:
  truths:
    - "main.go test coverage reaches 60%+"
    - "Server lifecycle tests verify startup and shutdown"
    - "Signal handling tests verify graceful shutdown on SIGTERM/SIGINT"
    - "Config validation tests catch invalid configuration"
    - "Health endpoint returns HTTP 200 OK"
  artifacts:
    - path: "main_test.go"
      provides: "Integration tests for main package"
      min_lines: 200
    - path: "testdata/valid_config.yaml"
      provides: "Valid test configuration fixture"
      contains: "nbuserver:"
    - path: "testdata/invalid_config.yaml"
      provides: "Invalid test configuration fixture"
  key_links:
    - from: "main_test.go"
      to: "main.go"
      via: "Server struct instantiation"
      pattern: "NewServer"
    - from: "main_test.go"
      to: "main.go"
      via: "validateConfig function"
      pattern: "validateConfig"
---

<objective>
Add integration tests for main.go, achieving 60%+ coverage of the main package.

Purpose: Addresses TEST-01 and TD-04 requirements. Main.go currently has 0% test coverage, representing a critical gap in the test suite. These tests verify server lifecycle, signal handling, and configuration validation.

Output: main_test.go with comprehensive integration tests, test fixture files in testdata/
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-test-coverage/04-RESEARCH.md
@main.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test fixtures for configuration tests</name>
  <files>testdata/valid_config.yaml, testdata/invalid_config.yaml</files>
  <action>
Create testdata directory and configuration fixture files:

1. Create `testdata/valid_config.yaml` with minimal valid configuration:

   - server.host: localhost
   - server.port: 0 (use random port for tests)
   - server.uri: /metrics
   - server.logname: /dev/null (no log file for tests)
   - server.scrapinginterval: 5m
   - nbuserver.scheme: https
   - nbuserver.host: localhost
   - nbuserver.port: 1556
   - nbuserver.apikey: test-api-key
   - nbuserver.apiversion: 13.0

2. Create `testdata/invalid_config.yaml` with invalid configuration:
   - Missing required fields (no nbuserver section)
   - server.port: -1 (invalid port)

Use YAML format matching models.Config structure. Keep fixtures minimal - just enough to test validation paths.
</action>
<verify>
Files exist:

```bash
ls testdata/valid_config.yaml testdata/invalid_config.yaml
```

  </verify>
  <done>Test fixture files exist with valid YAML syntax</done>
</task>

<task type="auto">
  <name>Task 2: Create main_test.go with Server lifecycle tests</name>
  <files>main_test.go</files>
  <action>
Create main_test.go with integration tests for the Server struct and supporting functions.

Test structure (use table-driven tests where appropriate):

1. **TestNewServer**: Verify NewServer creates server with correct fields

   - Creates server with valid config
   - Registry is non-nil
   - TelemetryManager is nil when OTel disabled
   - ErrorChan is buffered (non-blocking send)

2. **TestServerStartShutdown**: Integration test for server lifecycle

   - Create mock NBU server using testutil.NewMockServer().WithTLS()
   - Create test config pointing to mock server
   - Call server.Start() - verify no error
   - Make HTTP request to /health endpoint - verify 200 OK
   - Call server.Shutdown() - verify no error
   - Use random port (cfg.Server.Port = 0) to avoid port conflicts

3. **TestHealthHandler**: Unit test for healthHandler

   - Use httptest.NewRequest and httptest.NewRecorder
   - Call s.healthHandler(w, r)
   - Verify StatusCode is 200
   - Verify body contains "OK"

4. **TestValidateConfig**: Test configuration validation

   - Valid config path returns \*Config, nil error
   - Non-existent file returns nil, error containing "not found"
   - Invalid YAML returns nil, error containing "invalid"

5. **TestSetupLogging**: Test logging setup

   - Debug mode sets log level to Debug
   - Non-debug mode leaves default level

6. **TestWaitForShutdown**: Test signal handling

   - Create test that sends SIGTERM using syscall.Kill(syscall.Getpid(), syscall.SIGTERM)
   - Verify waitForShutdown returns nil (normal shutdown)
   - Use goroutine with done channel and timeout to prevent test hanging

7. **TestServerErrorPropagation**: Test error channel
   - Start server on invalid port (e.g., privileged port 80 without root)
   - Verify error is sent through ErrorChan()
   - Use select with timeout to verify error received

Import requirements:

- "context", "fmt", "net/http", "os", "os/signal", "syscall", "testing", "time"
- "github.com/stretchr/testify/assert", "github.com/stretchr/testify/require"
- "net/http/httptest"
- "github.com/fjacquet/nbu_exporter/internal/testutil"

Key patterns:

- Use t.Helper() for helper functions
- Use require._for setup, assert._ for verification
- Use defer for cleanup (server.Close(), server.Shutdown())
- Run with -race flag: add comment "// Run with: go test -race -v ."
  </action>
  <verify>
  Run tests with race detection:

```bash
go test -race -v . -count=1 2>&1 | head -50
```

Verify main package coverage reaches 60%+:

```bash
go test -cover . 2>&1 | grep coverage
```

  </verify>
  <done>main_test.go exists with 7 test functions, all tests pass with -race flag, coverage is 60%+</done>
</task>

<task type="auto">
  <name>Task 3: Add extractTraceContextMiddleware test</name>
  <files>main_test.go</files>
  <action>
Add test for extractTraceContextMiddleware function in main_test.go.

Add TestExtractTraceContextMiddleware:

1. Create a Server instance with mock telemetry manager (can be nil for this test)
2. Create inner handler that captures the request context
3. Wrap with extractTraceContextMiddleware
4. Create request with W3C traceparent header: "00-0af7651916cd43dd8448eb211c80319c-b7ad6b7169203331-01"
5. Call wrapped handler with httptest.NewRequest, httptest.NewRecorder
6. Verify the middleware doesn't panic/error
7. Verify response is passed through correctly

This tests that trace context extraction doesn't break normal request flow. Full trace context validation would require OTel setup, but basic functionality can be verified.
</action>
<verify>
Run all tests including new test:

```bash
go test -race -v . -run TestExtractTraceContext -count=1
```

Check final coverage:

```bash
go test -cover . 2>&1 | grep coverage
```

  </verify>
  <done>TestExtractTraceContextMiddleware passes, final coverage is 60%+</done>
</task>

</tasks>

<verification>
1. All tests pass: `go test -race -v . -count=1`
2. Coverage target met: `go test -cover .` shows 60%+ coverage
3. No race conditions: tests run cleanly with -race flag
4. Test fixtures valid: `cat testdata/*.yaml` shows valid YAML
</verification>

<success_criteria>

- main_test.go exists with comprehensive tests for Server, validateConfig, setupLogging, healthHandler, waitForShutdown
- Test fixtures exist in testdata/ directory
- All tests pass with `go test -race -v .`
- Coverage reaches 60%+ for main package
- Tests complete within 30 seconds (no hanging tests)
  </success_criteria>

<output>
After completion, create `.planning/phases/04-test-coverage/04-01-SUMMARY.md`
</output>
