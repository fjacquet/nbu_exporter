---
phase: 03-architecture-improvements
plan: 03
type: execute
wave: 3
depends_on: ["03-02"]
files_modified:
  - internal/exporter/prometheus.go
  - internal/exporter/netbackup.go
  - internal/exporter/metrics.go
  - internal/exporter/metrics_test.go
autonomous: true

must_haves:
  truths:
    - "Metric label values with pipe characters are handled correctly"
    - "Labels() method used directly instead of String() + Split()"
    - "Prometheus metrics output unchanged for normal label values"
  artifacts:
    - path: "internal/exporter/prometheus.go"
      provides: "Metric exposition using struct slices"
      contains: "key.Labels()"
    - path: "internal/exporter/netbackup.go"
      provides: "Metric collection returning struct types"
      contains: "StorageMetricValue"
  key_links:
    - from: "internal/exporter/prometheus.go"
      to: "internal/exporter/metrics.go"
      via: "Labels() method"
      pattern: "\\.Labels\\(\\)"
---

<objective>
Replace pipe-delimited string map keys with struct slices, using Labels() method directly for Prometheus metric exposition.

Purpose: Implements TD-03 - handles special characters safely in metric label values by avoiding string parsing.

Output: Refactored metric collection and exposition using typed structs instead of string concatenation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-architecture-improvements/03-RESEARCH.md

@internal/exporter/metrics.go
@internal/exporter/prometheus.go
@internal/exporter/netbackup.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add metric value types to metrics.go</name>
  <files>internal/exporter/metrics.go</files>
  <action>
Add value wrapper types that pair keys with their values:

```go
// StorageMetricValue pairs a StorageMetricKey with its metric value.
// Used for type-safe metric collection without string parsing.
type StorageMetricValue struct {
    Key   StorageMetricKey
    Value float64
}

// JobMetricValue pairs a JobMetricKey with its metric value.
// Used for type-safe metric collection without string parsing.
type JobMetricValue struct {
    Key   JobMetricKey
    Value float64
}

// JobStatusMetricValue pairs a JobStatusKey with its metric value.
// Used for type-safe metric collection without string parsing.
type JobStatusMetricValue struct {
    Key   JobStatusKey
    Value float64
}
```

Note: Keep the existing String() methods for backward compatibility and logging, but they won't be used for metric key storage.
  </action>
  <verify>

- `go build ./internal/exporter/...` compiles
- New types visible: `grep -n "MetricValue struct" internal/exporter/metrics.go`
  </verify>
  <done>
Metric value wrapper types added to metrics.go.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update netbackup.go to use typed collections</name>
  <files>internal/exporter/netbackup.go</files>
  <action>
Update FetchStorage and FetchJobDetails to use typed slices instead of string-keyed maps:

1. Update FetchStorage signature and implementation:

```go
// FetchStorage retrieves storage unit information and returns typed metric values.
// Returns a slice of StorageMetricValue instead of populating a string-keyed map.
func FetchStorage(ctx context.Context, client *NbuClient) ([]StorageMetricValue, error) {
    ctx, span := createSpan(ctx, client.tracer, "netbackup.fetch_storage", trace.SpanKindClient)
    if span != nil {
        defer span.End()
    }

    var storages models.Storages
    url := client.cfg.BuildURL(storagePath, map[string]string{
        QueryParamLimit:  pageLimit,
        QueryParamOffset: "0",
    })

    if err := client.FetchData(ctx, url, &storages); err != nil {
        if span != nil {
            span.RecordError(err)
            span.SetStatus(codes.Error, err.Error())
        }
        return nil, fmt.Errorf("failed to fetch storage data: %w", err)
    }

    var metrics []StorageMetricValue
    for _, data := range storages.Data {
        if data.Attributes.StorageType == storageTypeTape {
            continue
        }

        stuName := data.Attributes.Name
        stuType := data.Attributes.StorageServerType

        metrics = append(metrics, StorageMetricValue{
            Key:   StorageMetricKey{Name: stuName, Type: stuType, Size: sizeTypeFree},
            Value: float64(data.Attributes.FreeCapacityBytes),
        })
        metrics = append(metrics, StorageMetricValue{
            Key:   StorageMetricKey{Name: stuName, Type: stuType, Size: sizeTypeUsed},
            Value: float64(data.Attributes.UsedCapacityBytes),
        })
    }

    // Span attributes...
    if span != nil {
        attrs := []attribute.KeyValue{
            attribute.String(telemetry.AttrNetBackupEndpoint, storagePath),
            attribute.Int(telemetry.AttrNetBackupStorageUnits, len(storages.Data)),
            attribute.String(telemetry.AttrNetBackupAPIVersion, client.cfg.NbuServer.APIVersion),
        }
        span.SetAttributes(attrs...)
    }

    log.Debugf("Fetched storage data for %d storage units", len(storages.Data))
    return metrics, nil
}
```

1. Update FetchJobDetails to work with typed aggregation:
   - Change signature to accept typed accumulators
   - Return typed values for aggregation

2. Update FetchAllJobs to use typed collections:
   - Use map[JobMetricKey]float64 for intermediate aggregation
   - Convert to []JobMetricValue slice at the end

For jobs, we need a slightly different approach since we're aggregating:

```go
// FetchAllJobs aggregates job statistics using typed keys.
func FetchAllJobs(
    ctx context.Context,
    client *NbuClient,
    scrapingInterval string,
) (jobsSize []JobMetricValue, jobsCount []JobMetricValue, statusCount []JobStatusMetricValue, err error) {
    // Use typed maps for aggregation
    sizeMap := make(map[JobMetricKey]float64)
    countMap := make(map[JobMetricKey]float64)
    statusMap := make(map[JobStatusKey]float64)

    // ... existing pagination logic, but update keys directly in typed maps ...

    // Convert maps to slices
    for key, value := range sizeMap {
        jobsSize = append(jobsSize, JobMetricValue{Key: key, Value: value})
    }
    for key, value := range countMap {
        jobsCount = append(jobsCount, JobMetricValue{Key: key, Value: value})
    }
    for key, value := range statusMap {
        statusCount = append(statusCount, JobStatusMetricValue{Key: key, Value: value})
    }

    return jobsSize, jobsCount, statusCount, nil
}
```

Note: This is a significant refactor. The key insight is that we aggregate using struct keys (which can be map keys in Go since they are comparable), then convert to slices for the collector.
  </action>
  <verify>

- `go build ./internal/exporter/...` compiles
- Function signatures changed: `grep -n "func FetchStorage" internal/exporter/netbackup.go`
  </verify>
  <done>
FetchStorage and FetchAllJobs return typed slices instead of string-keyed maps.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update prometheus.go to use Labels() directly</name>
  <files>internal/exporter/prometheus.go</files>
  <action>
Update collector methods to use the new typed collections:

1. Update collectAllMetrics signature:

```go
func (c *NbuCollector) collectAllMetrics(ctx context.Context, span trace.Span) (
    storageMetrics []StorageMetricValue,
    jobsSize, jobsCount []JobMetricValue,
    jobsStatusCount []JobStatusMetricValue,
    storageErr, jobsErr error,
)
```

1. Update collectStorageMetrics:

```go
func (c *NbuCollector) collectStorageMetrics(ctx context.Context, span trace.Span) ([]StorageMetricValue, error) {
    metrics, err := FetchStorage(ctx, c.client)
    if err != nil {
        log.Errorf("Failed to fetch storage metrics: %v", err)
        c.recordFetchError(span, "storage_fetch_error", err)
        return nil, err
    }
    return metrics, nil
}
```

1. Update collectJobMetrics:

```go
func (c *NbuCollector) collectJobMetrics(ctx context.Context, span trace.Span) (
    jobsSize, jobsCount []JobMetricValue,
    jobsStatusCount []JobStatusMetricValue,
    err error,
) {
    jobsSize, jobsCount, jobsStatusCount, err = FetchAllJobs(ctx, c.client, c.cfg.Server.ScrapingInterval)
    if err != nil {
        log.Errorf("Failed to fetch job metrics: %v", err)
        c.recordFetchError(span, "jobs_fetch_error", err)
        return nil, nil, nil, err
    }
    return jobsSize, jobsCount, jobsStatusCount, nil
}
```

1. Update expose methods to use Labels() directly - THIS IS THE KEY CHANGE:

```go
func (c *NbuCollector) exposeStorageMetrics(ch chan<- prometheus.Metric, metrics []StorageMetricValue) {
    for _, m := range metrics {
        ch <- prometheus.MustNewConstMetric(
            c.nbuDiskSize,
            prometheus.GaugeValue,
            m.Value,
            m.Key.Labels()...,  // Use Labels() directly - no parsing!
        )
    }
}

func (c *NbuCollector) exposeJobSizeMetrics(ch chan<- prometheus.Metric, metrics []JobMetricValue) {
    for _, m := range metrics {
        ch <- prometheus.MustNewConstMetric(
            c.nbuJobsSize,
            prometheus.GaugeValue,
            m.Value,
            m.Key.Labels()...,  // Use Labels() directly
        )
    }
}

func (c *NbuCollector) exposeJobCountMetrics(ch chan<- prometheus.Metric, metrics []JobMetricValue) {
    for _, m := range metrics {
        ch <- prometheus.MustNewConstMetric(
            c.nbuJobsCount,
            prometheus.GaugeValue,
            m.Value,
            m.Key.Labels()...,
        )
    }
}

func (c *NbuCollector) exposeJobStatusMetrics(ch chan<- prometheus.Metric, metrics []JobStatusMetricValue) {
    for _, m := range metrics {
        ch <- prometheus.MustNewConstMetric(
            c.nbuJobsStatusCount,
            prometheus.GaugeValue,
            m.Value,
            m.Key.Labels()...,
        )
    }
}
```

1. Update exposeMetrics to pass typed slices:

```go
func (c *NbuCollector) exposeMetrics(ch chan<- prometheus.Metric,
    storageMetrics []StorageMetricValue,
    jobsSize, jobsCount []JobMetricValue,
    jobsStatusCount []JobStatusMetricValue) {

    c.exposeStorageMetrics(ch, storageMetrics)
    c.exposeJobSizeMetrics(ch, jobsSize)
    c.exposeJobCountMetrics(ch, jobsCount)
    c.exposeJobStatusMetrics(ch, jobsStatusCount)
    c.exposeAPIVersionMetric(ch)
}
```

1. Remove strings.Split imports if no longer needed
  </action>

  <verify>
- `go build ./internal/exporter/...` compiles
- No strings.Split on metric keys: `grep -n "strings.Split.*\"|\"" internal/exporter/prometheus.go` returns empty
- Labels() used: `grep -n "\.Labels()" internal/exporter/prometheus.go`
  </verify>
  <done>
Metric exposition uses Labels() method directly, no string parsing.
  </done>
</task>

<task type="auto">
  <name>Task 4: Add tests and verify metrics output</name>
  <files>internal/exporter/metrics_test.go</files>
  <action>
1. Add tests for metric value types and Labels() method:
```go
func TestStorageMetricKey_Labels(t *testing.T) {
    key := StorageMetricKey{Name: "pool|1", Type: "MEDIA_SERVER", Size: "free"}
    labels := key.Labels()

    if len(labels) != 3 {
        t.Fatalf("expected 3 labels, got %d", len(labels))
    }
    // Verify labels preserve special characters
    if labels[0] != "pool|1" {
        t.Errorf("expected 'pool|1', got '%s'", labels[0])
    }
}

func TestJobMetricKey_Labels(t *testing.T) {
    key := JobMetricKey{Action: "BACKUP", PolicyType: "VMware|Policy", Status: "0"}
    labels := key.Labels()

    if len(labels) != 3 {
        t.Fatalf("expected 3 labels, got %d", len(labels))
    }
    // Verify special chars preserved
    if labels[1] != "VMware|Policy" {
        t.Errorf("expected 'VMware|Policy', got '%s'", labels[1])
    }
}

func TestStorageMetricValue(t *testing.T) {
    value := StorageMetricValue{
        Key:   StorageMetricKey{Name: "test", Type: "DISK", Size: "free"},
        Value: 1024.0,
    }

    if value.Value != 1024.0 {
        t.Errorf("expected 1024.0, got %f", value.Value)
    }
    labels := value.Key.Labels()
    if labels[0] != "test" {
        t.Errorf("expected 'test', got '%s'", labels[0])
    }
}

```

2. Run full test suite:
```bash
go test ./... -race
```

1. Commit changes:

```bash
git add internal/exporter/metrics.go internal/exporter/netbackup.go \
        internal/exporter/prometheus.go internal/exporter/metrics_test.go
git commit -m "feat(03-03): use structured metric keys with Labels()

Implements TD-03: handle special characters safely in metric labels.

- Add StorageMetricValue, JobMetricValue, JobStatusMetricValue types
- FetchStorage returns []StorageMetricValue instead of map[string]float64
- FetchAllJobs returns typed slices instead of string-keyed maps
- exposeXxxMetrics use key.Labels() directly, no string parsing
- Labels with pipe characters handled correctly
- Prometheus output unchanged for standard label values

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

  </action>
  <verify>
- `go test ./... -race` passes
- `git log -1 --oneline` shows commit
- No strings.Split on metric keys in prometheus.go
  </verify>
  <done>
Structured metric keys implemented, Labels() used directly, special characters handled safely.
  </done>
</task>

</tasks>

<verification>
1. StorageMetricValue, JobMetricValue, JobStatusMetricValue types exist
2. FetchStorage returns []StorageMetricValue
3. FetchAllJobs returns typed slices
4. exposeXxxMetrics use key.Labels() directly
5. No strings.Split(key, "|") in prometheus.go metric exposition
6. Labels containing pipe characters are preserved correctly
7. All tests pass
</verification>

<success_criteria>

- Metric value wrapper types created
- FetchStorage and FetchAllJobs return typed collections
- Labels() method used directly for metric exposition
- Special characters in labels handled correctly
- Prometheus metrics output unchanged for normal values
- All tests pass with race detector
</success_criteria>

<output>
After completion, create `.planning/phases/03-architecture-improvements/03-03-SUMMARY.md`
</output>
