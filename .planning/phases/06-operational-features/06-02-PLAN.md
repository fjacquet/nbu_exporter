---
phase: 06-operational-features
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - internal/exporter/prometheus.go
  - internal/exporter/health.go
  - main.go
  - internal/exporter/health_test.go
autonomous: true

must_haves:
  truths:
    - "nbu_up metric is 1 when NBU API is reachable, 0 when all collections fail"
    - "nbu_last_scrape_timestamp_seconds shows Unix timestamp of last successful collection"
    - "Health endpoint returns 503 when NBU API is unreachable"
    - "Health endpoint returns 200 with connectivity test passing"
    - "Partial failure (storage OR jobs succeeds) keeps nbu_up=1"
  artifacts:
    - path: "internal/exporter/prometheus.go"
      provides: "nbu_up and nbu_last_scrape_timestamp_seconds metrics"
      contains: "nbuUp"
    - path: "internal/exporter/health.go"
      provides: "TestConnectivity method"
      exports: ["TestConnectivity"]
    - path: "main.go"
      provides: "Enhanced health endpoint with connectivity check"
      contains: "TestConnectivity"
  key_links:
    - from: "main.go"
      to: "internal/exporter/prometheus.go"
      via: "collector.TestConnectivity"
      pattern: "collector\\.TestConnectivity"
    - from: "internal/exporter/prometheus.go"
      to: "nbu_up metric"
      via: "Collect method"
      pattern: "MustNewConstMetric.*nbuUp"
---

<objective>
Implement health check with NetBackup connectivity verification and staleness tracking metrics.

Purpose: Operators need visibility into exporter health. The nbu_up metric (0/1) signals connectivity status for alerting. The nbu_last_scrape_timestamp_seconds metric enables staleness detection. The /health endpoint verifies NBU connectivity before returning success, enabling proper load balancer health checks.

Output: nbu_up and nbu_last_scrape_timestamp_seconds metrics exposed on /metrics, enhanced /health endpoint that tests NBU connectivity with 5-second timeout.
</objective>

<execution_context>
@~/.claude/agents/gsd-executor.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-operational-features/06-RESEARCH.md
@.planning/phases/06-operational-features/06-01-SUMMARY.md
@internal/exporter/prometheus.go
@main.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add nbu_up and nbu_last_scrape_timestamp_seconds metrics</name>
  <files>internal/exporter/prometheus.go</files>
  <action>
1. Add new metric descriptors to NbuCollector struct:
   ```go
   type NbuCollector struct {
       // ... existing fields ...
       nbuUp                 *prometheus.Desc
       nbuLastScrapeTime     *prometheus.Desc
       lastStorageScrapeTime time.Time  // Track last successful storage scrape
       lastJobsScrapeTime    time.Time  // Track last successful jobs scrape
       scrapeMu              sync.RWMutex
   }
   ```

2. Initialize descriptors in NewNbuCollector:

   ```go
   nbuUp: prometheus.NewDesc(
       "nbu_up",
       "1 if NetBackup API is reachable, 0 if all collections failed",
       nil, nil,
   ),
   nbuLastScrapeTime: prometheus.NewDesc(
       "nbu_last_scrape_timestamp_seconds",
       "Unix timestamp of the last successful metric collection",
       []string{"source"}, nil,  // source: "storage" or "jobs"
   ),
   ```

3. Add nbu_up and nbu_last_scrape_timestamp_seconds to Describe:

   ```go
   func (c *NbuCollector) Describe(ch chan<- *prometheus.Desc) {
       // ... existing descriptors ...
       ch <- c.nbuUp
       ch <- c.nbuLastScrapeTime
   }
   ```

4. Update collectStorageMetrics to track last success time:

   ```go
   func (c *NbuCollector) collectStorageMetrics(ctx context.Context, span trace.Span) ([]StorageMetricValue, error) {
       // ... existing cache/fetch logic ...

       // On success, update last scrape time
       if metrics != nil {
           c.scrapeMu.Lock()
           c.lastStorageScrapeTime = time.Now()
           c.scrapeMu.Unlock()
       }
       return metrics, err
   }
   ```

5. Update collectJobMetrics to track last success time:

   ```go
   func (c *NbuCollector) collectJobMetrics(ctx context.Context, span trace.Span) (
       jobsSize, jobsCount []JobMetricValue,
       jobsStatusCount []JobStatusMetricValue,
       err error,
   ) {
       // ... existing logic ...

       // On success, update last scrape time
       if err == nil {
           c.scrapeMu.Lock()
           c.lastJobsScrapeTime = time.Now()
           c.scrapeMu.Unlock()
       }
       return
   }
   ```

6. Update exposeMetrics to include nbu_up and timestamp metrics:

   ```go
   func (c *NbuCollector) exposeMetrics(ch chan<- prometheus.Metric, storageMetrics []StorageMetricValue, jobsSize, jobsCount []JobMetricValue, jobsStatusCount []JobStatusMetricValue, storageErr, jobsErr error) {
       // Expose nbu_up metric first (Prometheus convention)
       // up=1 if ANY collection succeeded, up=0 if ALL failed
       upValue := 0.0
       if storageErr == nil || jobsErr == nil {
           upValue = 1.0
       }
       ch <- prometheus.MustNewConstMetric(c.nbuUp, prometheus.GaugeValue, upValue)

       // Expose last scrape timestamps
       c.scrapeMu.RLock()
       if !c.lastStorageScrapeTime.IsZero() {
           ch <- prometheus.MustNewConstMetric(
               c.nbuLastScrapeTime,
               prometheus.GaugeValue,
               float64(c.lastStorageScrapeTime.Unix()),
               "storage",
           )
       }
       if !c.lastJobsScrapeTime.IsZero() {
           ch <- prometheus.MustNewConstMetric(
               c.nbuLastScrapeTime,
               prometheus.GaugeValue,
               float64(c.lastJobsScrapeTime.Unix()),
               "jobs",
           )
       }
       c.scrapeMu.RUnlock()

       // Expose existing metrics
       c.exposeStorageMetrics(ch, storageMetrics)
       c.exposeJobSizeMetrics(ch, jobsSize)
       c.exposeJobCountMetrics(ch, jobsCount)
       c.exposeJobStatusMetrics(ch, jobsStatusCount)
       c.exposeAPIVersionMetric(ch)
   }
   ```

7. Update Collect to pass errors to exposeMetrics:

   ```go
   func (c *NbuCollector) Collect(ch chan<- prometheus.Metric) {
       // ... existing collection logic ...

       // Pass errors to exposeMetrics for up metric calculation
       c.exposeMetrics(ch, storageMetrics, jobsSize, jobsCount, jobsStatusCount, storageErr, jobsErr)
   }
   ```

     </action>
     <verify>
       - `go build ./...` succeeds
       - `curl localhost:2112/metrics | grep nbu_up` shows metric
     </verify>
     <done>nbu_up and nbu_last_scrape_timestamp_seconds metrics exposed in Collect()</done>
   </task>

<task type="auto">
  <name>Task 2: Create TestConnectivity and enhance health endpoint</name>
  <files>internal/exporter/health.go, main.go</files>
  <action>
1. Create internal/exporter/health.go with TestConnectivity:
   ```go
   package exporter

import (
"context"
"fmt"
"time"
)

const healthCheckTimeout = 5 \* time.Second

// TestConnectivity verifies NetBackup API is reachable.
// Uses a lightweight API call with short timeout (5s).
// Returns nil if connectivity test passes, error otherwise.
func (c \*NbuCollector) TestConnectivity(ctx context.Context) error {
// Use provided context or create one with timeout
if \_, ok := ctx.Deadline(); !ok {
var cancel context.CancelFunc
ctx, cancel = context.WithTimeout(ctx, healthCheckTimeout)
defer cancel()
}

       // Use DetectAPIVersion as lightweight connectivity test
       _, err := c.client.DetectAPIVersion(ctx)
       if err != nil {
           return fmt.Errorf("NetBackup connectivity test failed: %w", err)
       }
       return nil

}

// IsHealthy returns true if the last collection was successful.
// This is a quick check without making an API call.
func (c \*NbuCollector) IsHealthy() bool {
c.scrapeMu.RLock()
defer c.scrapeMu.RUnlock()
// Healthy if we've had at least one successful scrape
return !c.lastStorageScrapeTime.IsZero() || !c.lastJobsScrapeTime.IsZero()
}

````

2. Update main.go healthHandler to verify connectivity:
```go
// healthHandler provides health check with NetBackup connectivity verification.
// Returns 200 OK if NBU API is reachable, 503 Service Unavailable otherwise.
// Used by load balancers and orchestrators (Kubernetes probes).
func (s *Server) healthHandler(w http.ResponseWriter, r *http.Request) {
    // Fast path: if no collector, just return OK (startup phase)
    if s.collector == nil {
        w.WriteHeader(http.StatusOK)
        fmt.Fprintf(w, "OK (starting)\n")
        return
    }

    // Test NetBackup connectivity with timeout
    ctx, cancel := context.WithTimeout(r.Context(), 5*time.Second)
    defer cancel()

    if err := s.collector.TestConnectivity(ctx); err != nil {
        log.Warnf("Health check failed: %v", err)
        w.WriteHeader(http.StatusServiceUnavailable)
        fmt.Fprintf(w, "UNHEALTHY: NetBackup API unreachable\n")
        return
    }

    w.WriteHeader(http.StatusOK)
    fmt.Fprintf(w, "OK\n")
}
````

3. Add import for context and time in main.go if not present.
   </action>
   <verify> - `go build ./...` succeeds - When NBU unreachable: `curl -v localhost:2112/health` returns 503 - When NBU reachable: `curl -v localhost:2112/health` returns 200
   </verify>
   <done>TestConnectivity method exists, health endpoint returns 503 on connectivity failure</done>
   </task>

</tasks>

<verification>
1. Build succeeds: `go build ./...`
2. Tests pass: `go test ./internal/exporter/... -v`
3. Race detector: `go test -race ./internal/exporter/...`
4. Manual test: Start exporter, verify nbu_up metric appears in /metrics output
5. Manual test: Block NBU server access, verify /health returns 503
</verification>

<success_criteria>

- nbu_up metric exposed (1 if any collection succeeds, 0 if all fail)
- nbu_last_scrape_timestamp_seconds metric exposed with source label
- Health endpoint tests NBU connectivity with 5-second timeout
- Health endpoint returns 503 when NBU unreachable
- Graceful degradation: partial success keeps nbu_up=1
- All tests pass with race detector
  </success_criteria>

<output>
After completion, create `.planning/phases/06-operational-features/06-02-SUMMARY.md`
</output>
